{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blackjack import BlackjackEnv\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlackjackAgent:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def policy(self, state):\n",
    "        agent_sum, _, _ = state\n",
    "        if agent_sum >= 20:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = BlackjackEnv()\n",
    "agent = BlackjackAgent()\n",
    "\n",
    "values = {}\n",
    "counts = {}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50000):\n",
    "    \n",
    "    trajectory = []\n",
    "    rewards = []\n",
    "    \n",
    "    state = env.reset()\n",
    "    trajectory.append(state)\n",
    "    \n",
    "    done = False\n",
    "    num_steps = 0\n",
    "    \n",
    "    while not done:\n",
    "        action = agent.policy(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        rewards.append(reward)\n",
    "        trajectory.append(state)\n",
    "        num_steps += 1\n",
    "    \n",
    "    rewards = np.array(rewards)\n",
    "    rewards = rewards * np.logspace(0, num_steps - 1, num_steps, base=0.99)\n",
    "    cumulative_rewards = np.cumsum(rewards[::-1])[::-1]\n",
    "    \n",
    "    visited = set()\n",
    "    for j, cumulative_reward in enumerate(cumulative_rewards):\n",
    "       \n",
    "        if not trajectory[j] in visited:\n",
    "            visited.add(trajectory[j])\n",
    "            values[trajectory[j]] = values.get(trajectory[j], 0) + cumulative_reward\n",
    "            counts[trajectory[j]] = counts.get(trajectory[j], 0) + 1\n",
    "\n",
    "for key in values.keys():\n",
    "    values[key] /= (counts[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Value iteration***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ControlAgent:\n",
    "    def __init__(self, eps=1e-2, debug=False):\n",
    "        \n",
    "        self.Q = {}\n",
    "        self.counts = {}\n",
    "        self.eps = eps\n",
    "        self.logs = {}\n",
    "        self.debug = debug\n",
    "\n",
    "        for i in range(32):\n",
    "            for j in range(11):\n",
    "                for k in range(2):\n",
    "                    self.Q[(i, j, k)] = np.random.randn(2)\n",
    "                    self.counts[(i, j, k)] = [1, 1]\n",
    "                    self.logs[(i, j, k)] = [[self.Q[(i, j, k)][0]], [self.Q[(i, j, k)][0]]]\n",
    "    \n",
    "    def policy(self, state, train=False):\n",
    "        \n",
    "        if train:\n",
    "            if np.random.rand() < self.eps:\n",
    "                return np.random.randint(2)\n",
    "            else:\n",
    "                return self.Q[state].argmax()\n",
    "        \n",
    "        else:\n",
    "            self.Q[state].argmax()\n",
    "            \n",
    "    \n",
    "    def update(self, trajectory, actions, rewards):\n",
    "        \n",
    "        assert(len(trajectory) == len(actions) + 1 and len(actions) == len(rewards))\n",
    "        \n",
    "        num_steps = len(actions)\n",
    "        rewards = np.array(rewards)\n",
    "        rewards = rewards * np.logspace(0, num_steps - 1, num_steps, base=0.99)\n",
    "        cumulative_rewards = np.cumsum(rewards[::-1])[::-1]\n",
    "        \n",
    "        visited = set()\n",
    "    \n",
    "        for j, action in enumerate(actions):\n",
    "            \n",
    "            state = trajectory[j]\n",
    "            G = cumulative_rewards[j]\n",
    "            \n",
    "            if not state in visited:\n",
    "                visited.add(state)\n",
    "                n = self.counts[state][action]\n",
    "                self.Q[state][action] = self.Q[state][action] * (n / (n + 1)) + G * (1 / (n + 1))\n",
    "                \n",
    "                if self.debug:\n",
    "                    self.logs[state][action].append(self.Q[state][action])\n",
    "                    \n",
    "                self.counts[state][action] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ControlAgent(eps=1e-2)\n",
    "wins = []\n",
    "\n",
    "for i in range(500000):\n",
    "    state = env.reset()\n",
    "    trajectory, actions, rewards = [state], [], []\n",
    "    \n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        action = agent.policy(state, train=True)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        actions.append(action)\n",
    "        rewards.append(reward)\n",
    "        trajectory.append(state)\n",
    "        \n",
    "    agent.update(trajectory, actions, rewards)\n",
    "    \n",
    "    wins.append(reward == 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39544\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(np.cumsum(wins) / np.arange(1, len(wins) + 1, 1))\n",
    "print((np.cumsum(wins) / np.arange(1, len(wins) + 1, 1))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pbshpc: \n",
      "                                                            Req'd  Req'd   Elap\n",
      "Job ID          Username Queue    Jobname    SessID NDS TSK Memory Time  S Time\n",
      "--------------- -------- -------- ---------- ------ --- --- ------ ----- - -----\n",
      "2372357.pbshpc  cs51804* standard triangle_*  21195   1   1    --  05:00 R 03:07\n",
      "2372386.pbshpc  cs51804* low      triangle_*  22747   1   6    --  05:00 R 02:28\n",
      "2372479.pbshpc  cs51804* standard STDIN       29367   1   1    --  06:00 R 01:08\n"
     ]
    }
   ],
   "source": [
    "!qstat -u cs5180404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
